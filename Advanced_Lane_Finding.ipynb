{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Sergey Morozov\n",
    "\n",
    "---\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "\n",
    "# constants\n",
    "import numpy as np\n",
    "IMAGE_SIZE=(720, 1280)\n",
    "CHESSBOARD_IMAGE_DIR = \"chessboard_images\"\n",
    "TEST_IMAGE_DIR = \"test_images\"\n",
    "OUTPUT_IMAGE_DIR = \"output_images\"\n",
    "OUTPUT_VIDEO_DIR = \"output_videos\"\n",
    "ABSOLUTE_SOBEL_X = (7, 20, 100)\n",
    "ABSOLUTE_SOBEL_Y = (7, 20, 100)\n",
    "MAGNITUDE_SOBEL = (3, 30, 100)\n",
    "DIRECTION_SOBEL = (31, 0.5, 1.0)\n",
    "S_CHANNEL_THRESHOLD = (170, 255)\n",
    "WARP_SRC = np.float32([(532, 496),\n",
    "                       (756, 496),\n",
    "                       (288, 664),\n",
    "                       (1016, 664)])\n",
    "WARP_DST = np.float32([(WARP_SRC[2][0], WARP_SRC[2][1] - 200),\n",
    "                       (WARP_SRC[3][0], WARP_SRC[3][1] - 200),\n",
    "                       (WARP_SRC[2][0], WARP_SRC[2][1]),\n",
    "                       (WARP_SRC[3][0], WARP_SRC[3][1])])\n",
    "SLIDING_WINDOW_PARAMS = (9, 100, 50)\n",
    "REGION_OF_INTEREST_VERTS = np.array([[\n",
    "            (0, IMAGE_SIZE[0]),\n",
    "            (IMAGE_SIZE[1] / 2, IMAGE_SIZE[0] / 2 + 45),\n",
    "            (IMAGE_SIZE[1] / 2, IMAGE_SIZE[0] / 2 + 45),\n",
    "            (IMAGE_SIZE[1],     IMAGE_SIZE[0])\n",
    "        ]], dtype = np.int32)\n",
    "\n",
    "# all lane finding code is in advanced_lane_finding.py\n",
    "from advanced_lane_finding import *\n",
    "\n",
    "# initialize class instance containing advanced lane line detection methods\n",
    "lane_finder = AdvancedLaneFinder(\n",
    "    image_size=IMAGE_SIZE,\n",
    "    chessboard_image_dir=CHESSBOARD_IMAGE_DIR,\n",
    "    absolute_sobel_x=ABSOLUTE_SOBEL_X,\n",
    "    absolute_sobel_y=ABSOLUTE_SOBEL_Y,\n",
    "    magnitude_sobel=MAGNITUDE_SOBEL,\n",
    "    direction_sobel=DIRECTION_SOBEL,\n",
    "    s_channel_thresh=S_CHANNEL_THRESHOLD,\n",
    "    warp_perspective=(WARP_SRC, WARP_DST),\n",
    "    sliding_window_params=SLIDING_WINDOW_PARAMS,\n",
    "    region_of_interest_verts=REGION_OF_INTEREST_VERTS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Camera Calibration Matrix and Distortion Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# camera calibrarion will happen once inside the pipeline\n",
    "\n",
    "# undistort chessboard image calibration2.jpg;\n",
    "# visially it is the mostly distorted image\n",
    "test_img = cv2.imread(os.path.join(CHESSBOARD_IMAGE_DIR, \"calibration2.jpg\"))\n",
    "\n",
    "# undistort test chessboard image\n",
    "test_img_undistorted = lane_finder.pipeline(image=test_img, stop_on_step='distortion_correction')\n",
    "\n",
    "# visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(test_img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(test_img_undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the initial set of chessboard images, provided by Udacity, image *calibration7.jpg* and *calibration15.jpg* had shape (1281, 721) while all other images had shape (1280, 720). These discrepancy led to inaccrate calculations. Images with incorrect shape (*calibration7.jpg* and *calibration15.jpg*) were cropped by 1 pixel and in this repository all images have (1280, 720) shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Distortion Correction to Raw Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for each test image apply pipeline steps and stop after undistortion applied\n",
    "test_img_paths = os.listdir(TEST_IMAGE_DIR)\n",
    "\n",
    "for fname in test_img_paths:\n",
    "    img = cv2.imread(os.path.join(TEST_IMAGE_DIR, fname))\n",
    "    img_undist = lane_finder.pipeline(image=img, stop_on_step='distortion_correction')\n",
    "    \n",
    "    # create output directory for images, if does not exist\n",
    "    if not os.path.isdir(OUTPUT_IMAGE_DIR):\n",
    "        os.mkdir(OUTPUT_IMAGE_DIR)\n",
    "    \n",
    "    # save undistorted image\n",
    "    cv2.imwrite(os.path.join(OUTPUT_IMAGE_DIR, fname[0:-4] + \"_undistorted.jpg\"), img_undist)\n",
    "    \n",
    "# visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "\n",
    "img = plt.imread(os.path.join(TEST_IMAGE_DIR, \"test1.jpg\"))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "\n",
    "img_undist = plt.imread(os.path.join(OUTPUT_IMAGE_DIR, \"test1_undistorted.jpg\"))\n",
    "ax2.imshow(img_undist)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Thresholded Binary Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for each test image apply pipeline steps and stop after thresholds applied\n",
    "test_img_paths = os.listdir(TEST_IMAGE_DIR)\n",
    "\n",
    "for fname in test_img_paths:\n",
    "    img = cv2.imread(os.path.join(TEST_IMAGE_DIR, fname))\n",
    "    img_thresh = lane_finder.pipeline(image=img, stop_on_step='apply_thresholds')\n",
    "    \n",
    "    # create output directory for images, if does not exist\n",
    "    if not os.path.isdir(OUTPUT_IMAGE_DIR):\n",
    "        os.mkdir(OUTPUT_IMAGE_DIR)\n",
    "        \n",
    "    # save thresholded image\n",
    "    cv2.imwrite(os.path.join(OUTPUT_IMAGE_DIR, fname[0:-4] + \"_thresholded.jpg\"), img_thresh)\n",
    "\n",
    "# visualize thresholded images (use difficult cases)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "\n",
    "img = plt.imread(os.path.join(TEST_IMAGE_DIR, \"test5.jpg\"))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "\n",
    "img_thresh = plt.imread(os.path.join(OUTPUT_IMAGE_DIR, \"test5_thresholded.jpg\"))\n",
    "ax2.imshow(img_thresh, cmap='gray')\n",
    "ax2.set_title('Thresholded Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for each test image apply pipeline steps and stop after region of interest applied\n",
    "test_img_paths = os.listdir(TEST_IMAGE_DIR)\n",
    "\n",
    "for fname in test_img_paths:\n",
    "    img = cv2.imread(os.path.join(TEST_IMAGE_DIR, fname))\n",
    "    img_reg_of_int = lane_finder.pipeline(image=img, stop_on_step='region_of_interest')\n",
    "    \n",
    "    # create output directory for images, if does not exist\n",
    "    if not os.path.isdir(OUTPUT_IMAGE_DIR):\n",
    "        os.mkdir(OUTPUT_IMAGE_DIR)\n",
    "    \n",
    "    # save region of interest image\n",
    "    cv2.imwrite(os.path.join(OUTPUT_IMAGE_DIR, fname[0:-4] + \"_region_of_interest.jpg\"), img_reg_of_int)\n",
    "\n",
    "# visualize region of interest\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "\n",
    "img = plt.imread(os.path.join(TEST_IMAGE_DIR, \"test3.jpg\"))\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "\n",
    "img_reg_of_int = plt.imread(os.path.join(OUTPUT_IMAGE_DIR, \"test3_region_of_interest.jpg\"))\n",
    "ax2.imshow(img_reg_of_int, cmap='gray')\n",
    "ax2.set_title('Region of Interest Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Perspective Transform (\"Birds-Eye View\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for each test image apply pipeline steps and stop after perspective transformation applied\n",
    "test_img_paths = os.listdir(TEST_IMAGE_DIR)\n",
    "\n",
    "for fname in test_img_paths:\n",
    "    img = cv2.imread(os.path.join(TEST_IMAGE_DIR, fname))\n",
    "    img_warped = lane_finder.pipeline(image=img, stop_on_step='warp_perspective')\n",
    "    \n",
    "    # create output directory for images, if does not exist\n",
    "    if not os.path.isdir(OUTPUT_IMAGE_DIR):\n",
    "        os.mkdir(OUTPUT_IMAGE_DIR)\n",
    "    \n",
    "    # save undistorted image\n",
    "    cv2.imwrite(os.path.join(OUTPUT_IMAGE_DIR, fname[0:-4] + \"_warped.jpg\"), img_warped)\n",
    "\n",
    "# visualize perspective transformation\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "\n",
    "img = plt.imread(os.path.join(TEST_IMAGE_DIR, \"test3.jpg\"))\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "\n",
    "img_warped = plt.imread(os.path.join(OUTPUT_IMAGE_DIR, \"test3_warped.jpg\"))\n",
    "ax2.imshow(img_warped, cmap='gray')\n",
    "ax2.set_title('Warped Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Lane Pixels and Fit to Find Lane Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for each test image apply pipeline steps and stop after fit polynomial step applied\n",
    "test_img_paths = os.listdir(TEST_IMAGE_DIR)\n",
    "\n",
    "for fname in test_img_paths:\n",
    "    # the following hack needed to start sliding window search for each new image\n",
    "    lane_finder._left_line.detected = False\n",
    "    lane_finder._right_line.detected = False\n",
    "    \n",
    "    image = cv2.imread(os.path.join(TEST_IMAGE_DIR, fname))\n",
    "    image_fit1 = lane_finder.pipeline(image, stop_on_step='fit_polynomial') \n",
    "    image_fit2 = lane_finder.pipeline(image, stop_on_step='fit_polynomial')\n",
    "    \n",
    "    # create output directory for images, if does not exist\n",
    "    if not os.path.isdir(OUTPUT_IMAGE_DIR):\n",
    "        os.mkdir(OUTPUT_IMAGE_DIR)\n",
    "    \n",
    "    # save fitted image\n",
    "    cv2.imwrite(os.path.join(OUTPUT_IMAGE_DIR, fname[0:-4] + \"_first_fit_polynomial.jpg\"), image_fit1)\n",
    "    cv2.imwrite(os.path.join(OUTPUT_IMAGE_DIR, fname[0:-4] + \"_second_fit_polynomial.jpg\"), image_fit2)\n",
    "\n",
    "# visualize sliding window search and fitted curve\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "\n",
    "ax1.imshow(cv2.imread(os.path.join(OUTPUT_IMAGE_DIR, 'test3_first_fit_polynomial.jpg')))\n",
    "ax1.set_title('Sliding Window Search Image', fontsize=30)\n",
    "\n",
    "ax2.imshow(cv2.imread(os.path.join(OUTPUT_IMAGE_DIR, 'test3_second_fit_polynomial.jpg')))\n",
    "ax2.set_title('Skip Sliding Window Search Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Curvature of Lane and Vehicle Position with Respect to Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
